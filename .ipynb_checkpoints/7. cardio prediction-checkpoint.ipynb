{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3bdc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435ad62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/DHEEPIKA/Downloads/heart.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00178541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd0eee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  \n",
       "0         2   2     3  \n",
       "1         0   0     3  \n",
       "2         0   0     3  \n",
       "3         2   1     3  \n",
       "4         1   3     2  \n",
       "...     ...  ..   ...  \n",
       "1020      2   0     2  \n",
       "1021      1   1     3  \n",
       "1022      1   1     2  \n",
       "1023      2   0     2  \n",
       "1024      1   1     3  \n",
       "\n",
       "[1025 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data.iloc[:,:13]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ab78ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1020    1\n",
       "1021    0\n",
       "1022    0\n",
       "1023    1\n",
       "1024    0\n",
       "Name: target, Length: 1025, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data.iloc[:,13]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f5f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a67e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(13,)))\n",
    "model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6f7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f69fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed2d620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 12.5401 - accuracy: 0.5166 - val_loss: 6.2508 - val_accuracy: 0.5347\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9547 - accuracy: 0.4782 - val_loss: 2.1658 - val_accuracy: 0.5139\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.6400 - accuracy: 0.5288 - val_loss: 0.8227 - val_accuracy: 0.6319\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7110 - accuracy: 0.5445 - val_loss: 1.1938 - val_accuracy: 0.6181\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.3837 - accuracy: 0.6056 - val_loss: 1.1486 - val_accuracy: 0.6250\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8370 - accuracy: 0.6056 - val_loss: 1.0301 - val_accuracy: 0.6528\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7532 - accuracy: 0.6073 - val_loss: 0.9718 - val_accuracy: 0.6597\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6490 - accuracy: 0.6178 - val_loss: 0.9562 - val_accuracy: 0.6528\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5255 - accuracy: 0.6108 - val_loss: 1.0246 - val_accuracy: 0.6319\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.6924 - accuracy: 0.6021 - val_loss: 0.9099 - val_accuracy: 0.6389\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3642 - accuracy: 0.5986 - val_loss: 1.1064 - val_accuracy: 0.5972\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.3963 - accuracy: 0.6335 - val_loss: 0.9746 - val_accuracy: 0.6111\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.2923 - accuracy: 0.6335 - val_loss: 0.9231 - val_accuracy: 0.6181\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1715 - accuracy: 0.6562 - val_loss: 0.8127 - val_accuracy: 0.6250\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0595 - accuracy: 0.6562 - val_loss: 0.8100 - val_accuracy: 0.6458\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0719 - accuracy: 0.6370 - val_loss: 0.9415 - val_accuracy: 0.5903\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0190 - accuracy: 0.6492 - val_loss: 0.7513 - val_accuracy: 0.6389\n",
      "Epoch 18/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0587 - accuracy: 0.6440 - val_loss: 0.7777 - val_accuracy: 0.6181\n",
      "Epoch 19/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.9566 - accuracy: 0.6492 - val_loss: 0.6905 - val_accuracy: 0.6528\n",
      "Epoch 20/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0128 - accuracy: 0.6143 - val_loss: 0.7701 - val_accuracy: 0.6319\n",
      "Epoch 21/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8827 - accuracy: 0.6422 - val_loss: 0.7854 - val_accuracy: 0.6250\n",
      "Epoch 22/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8575 - accuracy: 0.6440 - val_loss: 0.7399 - val_accuracy: 0.6250\n",
      "Epoch 23/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.9119 - accuracy: 0.6178 - val_loss: 0.6855 - val_accuracy: 0.6389\n",
      "Epoch 24/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.9618 - accuracy: 0.6230 - val_loss: 0.8247 - val_accuracy: 0.6111\n",
      "Epoch 25/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7802 - accuracy: 0.6719 - val_loss: 0.7099 - val_accuracy: 0.6528\n",
      "Epoch 26/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.6579 - val_loss: 0.7141 - val_accuracy: 0.6250\n",
      "Epoch 27/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.6684 - val_loss: 0.6310 - val_accuracy: 0.6667\n",
      "Epoch 28/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.6667 - val_loss: 0.7076 - val_accuracy: 0.6319\n",
      "Epoch 29/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7545 - accuracy: 0.6632 - val_loss: 0.6771 - val_accuracy: 0.6528\n",
      "Epoch 30/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.6719 - val_loss: 0.8828 - val_accuracy: 0.5903\n",
      "Epoch 31/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.6632 - val_loss: 0.6596 - val_accuracy: 0.6458\n",
      "Epoch 32/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.6684 - val_loss: 0.7335 - val_accuracy: 0.6250\n",
      "Epoch 33/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.6545 - val_loss: 0.6462 - val_accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6876 - val_loss: 0.6466 - val_accuracy: 0.6736\n",
      "Epoch 35/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7033 - val_loss: 0.6099 - val_accuracy: 0.6736\n",
      "Epoch 36/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6928 - val_loss: 0.6885 - val_accuracy: 0.6389\n",
      "Epoch 37/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.7051 - val_loss: 0.6584 - val_accuracy: 0.6389\n",
      "Epoch 38/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.7208 - val_loss: 0.6192 - val_accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7138 - val_loss: 0.6137 - val_accuracy: 0.6806\n",
      "Epoch 40/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6894 - val_loss: 0.7685 - val_accuracy: 0.6042\n",
      "Epoch 41/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.7016 - val_loss: 0.6255 - val_accuracy: 0.6806\n",
      "Epoch 42/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7208 - val_loss: 0.5840 - val_accuracy: 0.6875\n",
      "Epoch 43/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7068 - val_loss: 0.6115 - val_accuracy: 0.6736\n",
      "Epoch 44/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.6789 - val_loss: 0.6924 - val_accuracy: 0.6597\n",
      "Epoch 45/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6894 - val_loss: 0.6145 - val_accuracy: 0.6806\n",
      "Epoch 46/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.7277 - val_loss: 0.6017 - val_accuracy: 0.6806\n",
      "Epoch 47/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7208 - val_loss: 0.5794 - val_accuracy: 0.6875\n",
      "Epoch 48/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7365 - val_loss: 0.5952 - val_accuracy: 0.6806\n",
      "Epoch 49/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7208 - val_loss: 0.6909 - val_accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7330 - val_loss: 0.5900 - val_accuracy: 0.6736\n",
      "Epoch 51/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7417 - val_loss: 0.5919 - val_accuracy: 0.6806\n",
      "Epoch 52/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7469 - val_loss: 0.6058 - val_accuracy: 0.6806\n",
      "Epoch 53/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7243 - val_loss: 0.5835 - val_accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7347 - val_loss: 0.6113 - val_accuracy: 0.6875\n",
      "Epoch 55/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7382 - val_loss: 0.5804 - val_accuracy: 0.6875\n",
      "Epoch 56/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7504 - val_loss: 0.5735 - val_accuracy: 0.7083\n",
      "Epoch 57/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7644 - val_loss: 0.5590 - val_accuracy: 0.6944\n",
      "Epoch 58/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7417 - val_loss: 0.6162 - val_accuracy: 0.6944\n",
      "Epoch 59/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7400 - val_loss: 0.5836 - val_accuracy: 0.7014\n",
      "Epoch 60/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7435 - val_loss: 0.5939 - val_accuracy: 0.6736\n",
      "Epoch 61/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7627 - val_loss: 0.5673 - val_accuracy: 0.6875\n",
      "Epoch 62/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7539 - val_loss: 0.5617 - val_accuracy: 0.7153\n",
      "Epoch 63/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7801 - val_loss: 0.5681 - val_accuracy: 0.6875\n",
      "Epoch 64/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7714 - val_loss: 0.5606 - val_accuracy: 0.6944\n",
      "Epoch 65/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7941 - val_loss: 0.5551 - val_accuracy: 0.6875\n",
      "Epoch 66/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7714 - val_loss: 0.5568 - val_accuracy: 0.7153\n",
      "Epoch 67/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7853 - val_loss: 0.5723 - val_accuracy: 0.7083\n",
      "Epoch 68/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7504 - val_loss: 0.5351 - val_accuracy: 0.7222\n",
      "Epoch 69/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7609 - val_loss: 0.5490 - val_accuracy: 0.7014\n",
      "Epoch 70/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7627 - val_loss: 0.5610 - val_accuracy: 0.7222\n",
      "Epoch 71/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7818 - val_loss: 0.5887 - val_accuracy: 0.6875\n",
      "Epoch 72/300\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7731 - val_loss: 0.5536 - val_accuracy: 0.7083\n",
      "Epoch 73/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7714 - val_loss: 0.5295 - val_accuracy: 0.7431\n",
      "Epoch 74/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.8010 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
      "Epoch 75/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.8080 - val_loss: 0.5436 - val_accuracy: 0.7153\n",
      "Epoch 76/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7853 - val_loss: 0.5527 - val_accuracy: 0.7153\n",
      "Epoch 77/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7801 - val_loss: 0.5763 - val_accuracy: 0.7083\n",
      "Epoch 78/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8202 - val_loss: 0.5350 - val_accuracy: 0.7153\n",
      "Epoch 79/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8098 - val_loss: 0.5474 - val_accuracy: 0.7153\n",
      "Epoch 80/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7906 - val_loss: 0.5336 - val_accuracy: 0.7222\n",
      "Epoch 81/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7818 - val_loss: 0.5513 - val_accuracy: 0.7083\n",
      "Epoch 82/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8115 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 83/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7784 - val_loss: 0.5509 - val_accuracy: 0.7292\n",
      "Epoch 84/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8045 - val_loss: 0.6668 - val_accuracy: 0.6875\n",
      "Epoch 85/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7993 - val_loss: 0.5797 - val_accuracy: 0.7292\n",
      "Epoch 86/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7818 - val_loss: 0.5856 - val_accuracy: 0.7083\n",
      "Epoch 87/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7749 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 88/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8028 - val_loss: 0.5566 - val_accuracy: 0.7222\n",
      "Epoch 89/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8045 - val_loss: 0.6611 - val_accuracy: 0.6875\n",
      "Epoch 90/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8063 - val_loss: 0.5364 - val_accuracy: 0.7431\n",
      "Epoch 91/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8133 - val_loss: 0.5412 - val_accuracy: 0.7083\n",
      "Epoch 92/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8080 - val_loss: 0.6312 - val_accuracy: 0.6806\n",
      "Epoch 93/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8272 - val_loss: 0.5747 - val_accuracy: 0.7083\n",
      "Epoch 94/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8045 - val_loss: 0.5727 - val_accuracy: 0.7014\n",
      "Epoch 95/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8202 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
      "Epoch 96/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8098 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 97/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8185 - val_loss: 0.5300 - val_accuracy: 0.7361\n",
      "Epoch 98/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8080 - val_loss: 0.5498 - val_accuracy: 0.7361\n",
      "Epoch 99/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8133 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 100/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.8080 - val_loss: 0.5481 - val_accuracy: 0.7361\n",
      "Epoch 101/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8185 - val_loss: 0.5490 - val_accuracy: 0.7222\n",
      "Epoch 102/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8168 - val_loss: 0.5292 - val_accuracy: 0.7361\n",
      "Epoch 103/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8482 - val_loss: 0.5558 - val_accuracy: 0.7153\n",
      "Epoch 104/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8464 - val_loss: 0.5361 - val_accuracy: 0.7361\n",
      "Epoch 105/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8394 - val_loss: 0.5492 - val_accuracy: 0.7222\n",
      "Epoch 106/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8255 - val_loss: 0.5624 - val_accuracy: 0.7292\n",
      "Epoch 107/300\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8412 - val_loss: 0.5349 - val_accuracy: 0.7361\n",
      "Epoch 108/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8202 - val_loss: 0.5529 - val_accuracy: 0.7222\n",
      "Epoch 109/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8447 - val_loss: 0.5457 - val_accuracy: 0.7431\n",
      "Epoch 110/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8482 - val_loss: 0.5568 - val_accuracy: 0.7292\n",
      "Epoch 111/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8394 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 112/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8342 - val_loss: 0.5558 - val_accuracy: 0.7153\n",
      "Epoch 113/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8080 - val_loss: 0.6258 - val_accuracy: 0.6944\n",
      "Epoch 114/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8133 - val_loss: 0.5750 - val_accuracy: 0.7222\n",
      "Epoch 115/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8482 - val_loss: 0.5500 - val_accuracy: 0.7569\n",
      "Epoch 116/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8150 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 117/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8237 - val_loss: 0.5460 - val_accuracy: 0.7222\n",
      "Epoch 118/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8412 - val_loss: 0.5857 - val_accuracy: 0.7153\n",
      "Epoch 119/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8255 - val_loss: 0.5726 - val_accuracy: 0.7292\n",
      "Epoch 120/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8307 - val_loss: 0.5516 - val_accuracy: 0.7361\n",
      "Epoch 121/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8447 - val_loss: 0.6353 - val_accuracy: 0.7014\n",
      "Epoch 122/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8290 - val_loss: 0.5563 - val_accuracy: 0.7361\n",
      "Epoch 123/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8185 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
      "Epoch 124/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8394 - val_loss: 0.5970 - val_accuracy: 0.7153\n",
      "Epoch 125/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8551 - val_loss: 0.5282 - val_accuracy: 0.7361\n",
      "Epoch 126/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8569 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
      "Epoch 127/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8482 - val_loss: 0.5358 - val_accuracy: 0.7361\n",
      "Epoch 128/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8429 - val_loss: 0.5267 - val_accuracy: 0.7431\n",
      "Epoch 129/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8325 - val_loss: 0.5580 - val_accuracy: 0.7292\n",
      "Epoch 130/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8377 - val_loss: 0.5821 - val_accuracy: 0.7222\n",
      "Epoch 131/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8464 - val_loss: 0.5655 - val_accuracy: 0.7569\n",
      "Epoch 132/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8185 - val_loss: 0.5539 - val_accuracy: 0.7361\n",
      "Epoch 133/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8412 - val_loss: 0.5689 - val_accuracy: 0.7292\n",
      "Epoch 134/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8272 - val_loss: 0.6015 - val_accuracy: 0.7431\n",
      "Epoch 135/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8604 - val_loss: 0.5445 - val_accuracy: 0.7361\n",
      "Epoch 136/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8307 - val_loss: 0.5387 - val_accuracy: 0.7222\n",
      "Epoch 137/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8150 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8377 - val_loss: 0.5723 - val_accuracy: 0.7222\n",
      "Epoch 139/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8220 - val_loss: 0.5306 - val_accuracy: 0.7361\n",
      "Epoch 140/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8464 - val_loss: 0.5653 - val_accuracy: 0.7569\n",
      "Epoch 141/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8743 - val_loss: 0.5872 - val_accuracy: 0.7431\n",
      "Epoch 142/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.8377 - val_loss: 0.5258 - val_accuracy: 0.7361\n",
      "Epoch 143/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8551 - val_loss: 0.5410 - val_accuracy: 0.7361\n",
      "Epoch 144/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8482 - val_loss: 0.5507 - val_accuracy: 0.7292\n",
      "Epoch 145/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8412 - val_loss: 0.5537 - val_accuracy: 0.7361\n",
      "Epoch 146/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8569 - val_loss: 0.5396 - val_accuracy: 0.7361\n",
      "Epoch 147/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8482 - val_loss: 0.5701 - val_accuracy: 0.7569\n",
      "Epoch 148/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8325 - val_loss: 0.5669 - val_accuracy: 0.7361\n",
      "Epoch 149/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8429 - val_loss: 0.5438 - val_accuracy: 0.7639\n",
      "Epoch 150/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8412 - val_loss: 0.5811 - val_accuracy: 0.7222\n",
      "Epoch 151/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8360 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 152/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8429 - val_loss: 0.5304 - val_accuracy: 0.7431\n",
      "Epoch 153/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8168 - val_loss: 0.5635 - val_accuracy: 0.7431\n",
      "Epoch 154/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8517 - val_loss: 0.6202 - val_accuracy: 0.7014\n",
      "Epoch 155/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8429 - val_loss: 0.5594 - val_accuracy: 0.7361\n",
      "Epoch 156/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8517 - val_loss: 0.5471 - val_accuracy: 0.7222\n",
      "Epoch 157/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8586 - val_loss: 0.5504 - val_accuracy: 0.7431\n",
      "Epoch 158/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8639 - val_loss: 0.5096 - val_accuracy: 0.7569\n",
      "Epoch 159/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8586 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
      "Epoch 160/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8168 - val_loss: 0.5511 - val_accuracy: 0.7222\n",
      "Epoch 161/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8464 - val_loss: 0.5889 - val_accuracy: 0.7361\n",
      "Epoch 162/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8394 - val_loss: 0.5061 - val_accuracy: 0.7361\n",
      "Epoch 163/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8674 - val_loss: 0.5895 - val_accuracy: 0.7292\n",
      "Epoch 164/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8604 - val_loss: 0.5501 - val_accuracy: 0.7431\n",
      "Epoch 165/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8674 - val_loss: 0.5116 - val_accuracy: 0.7431\n",
      "Epoch 166/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8621 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 167/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8709 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 168/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8499 - val_loss: 0.5182 - val_accuracy: 0.7361\n",
      "Epoch 169/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8377 - val_loss: 0.5362 - val_accuracy: 0.7639\n",
      "Epoch 170/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8621 - val_loss: 0.5324 - val_accuracy: 0.7361\n",
      "Epoch 171/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8586 - val_loss: 0.5287 - val_accuracy: 0.7569\n",
      "Epoch 172/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8604 - val_loss: 0.5467 - val_accuracy: 0.7361\n",
      "Epoch 173/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8307 - val_loss: 0.5221 - val_accuracy: 0.7431\n",
      "Epoch 174/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8621 - val_loss: 0.5221 - val_accuracy: 0.7431\n",
      "Epoch 175/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8726 - val_loss: 0.5465 - val_accuracy: 0.7569\n",
      "Epoch 176/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8726 - val_loss: 0.5301 - val_accuracy: 0.7361\n",
      "Epoch 177/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8656 - val_loss: 0.5315 - val_accuracy: 0.7431\n",
      "Epoch 178/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8569 - val_loss: 0.5190 - val_accuracy: 0.7361\n",
      "Epoch 179/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8586 - val_loss: 0.5381 - val_accuracy: 0.7431\n",
      "Epoch 180/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8499 - val_loss: 0.5317 - val_accuracy: 0.7500\n",
      "Epoch 181/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8586 - val_loss: 0.5592 - val_accuracy: 0.7361\n",
      "Epoch 182/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.8691 - val_loss: 0.5110 - val_accuracy: 0.7639\n",
      "Epoch 183/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8517 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 184/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8691 - val_loss: 0.5289 - val_accuracy: 0.7361\n",
      "Epoch 185/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8674 - val_loss: 0.5168 - val_accuracy: 0.7639\n",
      "Epoch 186/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8482 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
      "Epoch 187/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8586 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
      "Epoch 188/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8621 - val_loss: 0.5502 - val_accuracy: 0.7431\n",
      "Epoch 189/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8534 - val_loss: 0.5039 - val_accuracy: 0.7569\n",
      "Epoch 190/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8604 - val_loss: 0.5304 - val_accuracy: 0.7431\n",
      "Epoch 191/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8674 - val_loss: 0.5230 - val_accuracy: 0.7569\n",
      "Epoch 192/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8639 - val_loss: 0.5499 - val_accuracy: 0.7361\n",
      "Epoch 193/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8551 - val_loss: 0.5190 - val_accuracy: 0.7431\n",
      "Epoch 194/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8831 - val_loss: 0.5450 - val_accuracy: 0.7569\n",
      "Epoch 195/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8761 - val_loss: 0.5906 - val_accuracy: 0.7708\n",
      "Epoch 196/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8691 - val_loss: 0.5635 - val_accuracy: 0.7569\n",
      "Epoch 197/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8447 - val_loss: 0.5709 - val_accuracy: 0.7431\n",
      "Epoch 198/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8778 - val_loss: 0.5425 - val_accuracy: 0.7639\n",
      "Epoch 199/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.8691 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 200/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8691 - val_loss: 0.5098 - val_accuracy: 0.7569\n",
      "Epoch 201/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8621 - val_loss: 0.5356 - val_accuracy: 0.7569\n",
      "Epoch 202/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8778 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
      "Epoch 203/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8709 - val_loss: 0.5140 - val_accuracy: 0.7569\n",
      "Epoch 204/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8534 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 205/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8709 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
      "Epoch 206/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8726 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
      "Epoch 207/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8674 - val_loss: 0.5480 - val_accuracy: 0.7431\n",
      "Epoch 208/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8569 - val_loss: 0.5512 - val_accuracy: 0.7639\n",
      "Epoch 209/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8743 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
      "Epoch 210/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8726 - val_loss: 0.5209 - val_accuracy: 0.7639\n",
      "Epoch 211/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8726 - val_loss: 0.5050 - val_accuracy: 0.7569\n",
      "Epoch 212/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8848 - val_loss: 0.5751 - val_accuracy: 0.7569\n",
      "Epoch 213/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8743 - val_loss: 0.5235 - val_accuracy: 0.7569\n",
      "Epoch 214/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8813 - val_loss: 0.5460 - val_accuracy: 0.7778\n",
      "Epoch 215/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8586 - val_loss: 0.5608 - val_accuracy: 0.7639\n",
      "Epoch 216/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.8726 - val_loss: 0.5317 - val_accuracy: 0.7500\n",
      "Epoch 217/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8691 - val_loss: 0.5274 - val_accuracy: 0.7708\n",
      "Epoch 218/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8709 - val_loss: 0.5475 - val_accuracy: 0.7361\n",
      "Epoch 219/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8674 - val_loss: 0.5658 - val_accuracy: 0.7500\n",
      "Epoch 220/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8569 - val_loss: 0.5355 - val_accuracy: 0.7778\n",
      "Epoch 221/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8778 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
      "Epoch 222/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8726 - val_loss: 0.5466 - val_accuracy: 0.7708\n",
      "Epoch 223/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8674 - val_loss: 0.5675 - val_accuracy: 0.7778\n",
      "Epoch 224/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8621 - val_loss: 0.5323 - val_accuracy: 0.7847\n",
      "Epoch 225/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8656 - val_loss: 0.5687 - val_accuracy: 0.7778\n",
      "Epoch 226/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8778 - val_loss: 0.5669 - val_accuracy: 0.7639\n",
      "Epoch 227/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8743 - val_loss: 0.5816 - val_accuracy: 0.7986\n",
      "Epoch 228/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8569 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
      "Epoch 229/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3041 - accuracy: 0.8796 - val_loss: 0.5359 - val_accuracy: 0.7639\n",
      "Epoch 230/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8796 - val_loss: 0.5346 - val_accuracy: 0.7639\n",
      "Epoch 231/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8796 - val_loss: 0.5172 - val_accuracy: 0.7639\n",
      "Epoch 232/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8743 - val_loss: 0.5254 - val_accuracy: 0.7708\n",
      "Epoch 233/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8726 - val_loss: 0.5178 - val_accuracy: 0.7778\n",
      "Epoch 234/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8848 - val_loss: 0.5635 - val_accuracy: 0.7639\n",
      "Epoch 235/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8778 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 236/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8586 - val_loss: 0.5592 - val_accuracy: 0.7569\n",
      "Epoch 237/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3211 - accuracy: 0.8726 - val_loss: 0.5361 - val_accuracy: 0.7639\n",
      "Epoch 238/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8743 - val_loss: 0.5710 - val_accuracy: 0.7222\n",
      "Epoch 239/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8534 - val_loss: 0.5106 - val_accuracy: 0.7639\n",
      "Epoch 240/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8534 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 241/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8778 - val_loss: 0.5206 - val_accuracy: 0.7847\n",
      "Epoch 242/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8586 - val_loss: 0.5216 - val_accuracy: 0.7778\n",
      "Epoch 243/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8569 - val_loss: 0.5735 - val_accuracy: 0.7639\n",
      "Epoch 244/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8813 - val_loss: 0.5123 - val_accuracy: 0.7569\n",
      "Epoch 245/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8499 - val_loss: 0.5472 - val_accuracy: 0.7639\n",
      "Epoch 246/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8691 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 247/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8761 - val_loss: 0.4988 - val_accuracy: 0.7917\n",
      "Epoch 248/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8709 - val_loss: 0.5375 - val_accuracy: 0.7569\n",
      "Epoch 249/300\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3096 - accuracy: 0.8796 - val_loss: 0.5332 - val_accuracy: 0.7708\n",
      "Epoch 250/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8743 - val_loss: 0.5285 - val_accuracy: 0.7569\n",
      "Epoch 251/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8604 - val_loss: 0.5508 - val_accuracy: 0.7569\n",
      "Epoch 252/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2816 - accuracy: 0.8901 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
      "Epoch 253/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8517 - val_loss: 0.5206 - val_accuracy: 0.7639\n",
      "Epoch 254/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8726 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 255/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8813 - val_loss: 0.5847 - val_accuracy: 0.7986\n",
      "Epoch 256/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8813 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 257/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8813 - val_loss: 0.5522 - val_accuracy: 0.7778\n",
      "Epoch 258/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3012 - accuracy: 0.8848 - val_loss: 0.5744 - val_accuracy: 0.7847\n",
      "Epoch 259/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8691 - val_loss: 0.5384 - val_accuracy: 0.7639\n",
      "Epoch 260/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8831 - val_loss: 0.5008 - val_accuracy: 0.7847\n",
      "Epoch 261/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8778 - val_loss: 0.5445 - val_accuracy: 0.7708\n",
      "Epoch 262/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2896 - accuracy: 0.8761 - val_loss: 0.5141 - val_accuracy: 0.7847\n",
      "Epoch 263/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8796 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 264/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8953 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
      "Epoch 265/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2895 - accuracy: 0.8901 - val_loss: 0.5371 - val_accuracy: 0.7639\n",
      "Epoch 266/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8866 - val_loss: 0.4948 - val_accuracy: 0.7639\n",
      "Epoch 267/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8726 - val_loss: 0.6214 - val_accuracy: 0.7708\n",
      "Epoch 268/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8778 - val_loss: 0.5064 - val_accuracy: 0.7639\n",
      "Epoch 269/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8918 - val_loss: 0.5323 - val_accuracy: 0.7639\n",
      "Epoch 270/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8778 - val_loss: 0.5097 - val_accuracy: 0.7778\n",
      "Epoch 271/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8883 - val_loss: 0.5202 - val_accuracy: 0.7639\n",
      "Epoch 272/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.8866 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 273/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.8831 - val_loss: 0.5626 - val_accuracy: 0.7708\n",
      "Epoch 274/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8674 - val_loss: 0.4901 - val_accuracy: 0.7917\n",
      "Epoch 275/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.9040 - val_loss: 0.5259 - val_accuracy: 0.7917\n",
      "Epoch 276/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8848 - val_loss: 0.5281 - val_accuracy: 0.7847\n",
      "Epoch 277/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8674 - val_loss: 0.5025 - val_accuracy: 0.7639\n",
      "Epoch 278/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8726 - val_loss: 0.5424 - val_accuracy: 0.7639\n",
      "Epoch 279/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8778 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
      "Epoch 280/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2793 - accuracy: 0.8901 - val_loss: 0.5419 - val_accuracy: 0.7639\n",
      "Epoch 281/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2829 - accuracy: 0.8743 - val_loss: 0.5924 - val_accuracy: 0.7917\n",
      "Epoch 282/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8743 - val_loss: 0.5300 - val_accuracy: 0.7917\n",
      "Epoch 283/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8831 - val_loss: 0.5574 - val_accuracy: 0.7639\n",
      "Epoch 284/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.8796 - val_loss: 0.5576 - val_accuracy: 0.7778\n",
      "Epoch 285/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8726 - val_loss: 0.5918 - val_accuracy: 0.7986\n",
      "Epoch 286/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8691 - val_loss: 0.6758 - val_accuracy: 0.7778\n",
      "Epoch 287/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8604 - val_loss: 0.4837 - val_accuracy: 0.7986\n",
      "Epoch 288/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2933 - accuracy: 0.8796 - val_loss: 0.5004 - val_accuracy: 0.7639\n",
      "Epoch 289/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8901 - val_loss: 0.5261 - val_accuracy: 0.7847\n",
      "Epoch 290/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8778 - val_loss: 0.5513 - val_accuracy: 0.7847\n",
      "Epoch 291/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8988 - val_loss: 0.5139 - val_accuracy: 0.8194\n",
      "Epoch 292/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8918 - val_loss: 0.4959 - val_accuracy: 0.7778\n",
      "Epoch 293/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.8935 - val_loss: 0.5181 - val_accuracy: 0.7639\n",
      "Epoch 294/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.8831 - val_loss: 0.5232 - val_accuracy: 0.7986\n",
      "Epoch 295/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.8866 - val_loss: 0.5384 - val_accuracy: 0.7847\n",
      "Epoch 296/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8796 - val_loss: 0.5445 - val_accuracy: 0.7569\n",
      "Epoch 297/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8778 - val_loss: 0.5342 - val_accuracy: 0.7708\n",
      "Epoch 298/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.8970 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
      "Epoch 299/300\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8918 - val_loss: 0.5351 - val_accuracy: 0.7569\n",
      "Epoch 300/300\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8447 - val_loss: 0.5308 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8608574f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train , batch_size = 32,epochs = 300,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f52daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8214\n",
      "Test Accuracy: 0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5160115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99681324],\n",
       "       [0.99746066],\n",
       "       [0.04860427],\n",
       "       [0.9786894 ],\n",
       "       [0.09245726],\n",
       "       [0.6174895 ],\n",
       "       [0.06399499],\n",
       "       [0.09350409],\n",
       "       [0.89039344],\n",
       "       [0.27103233],\n",
       "       [0.99769604],\n",
       "       [0.02446905],\n",
       "       [0.9295209 ],\n",
       "       [0.9997745 ],\n",
       "       [0.09806429],\n",
       "       [0.9567987 ],\n",
       "       [0.0726198 ],\n",
       "       [0.999927  ],\n",
       "       [0.9558328 ],\n",
       "       [0.07588718],\n",
       "       [0.43353343],\n",
       "       [0.13437232],\n",
       "       [0.43791234],\n",
       "       [0.00829688],\n",
       "       [0.43353343],\n",
       "       [0.9818114 ],\n",
       "       [0.9383045 ],\n",
       "       [0.38983005],\n",
       "       [0.01215212],\n",
       "       [0.76693016],\n",
       "       [0.5571133 ],\n",
       "       [0.5315781 ],\n",
       "       [0.6264389 ],\n",
       "       [0.99746066],\n",
       "       [0.9662897 ],\n",
       "       [0.93457305],\n",
       "       [0.43353343],\n",
       "       [0.4962469 ],\n",
       "       [0.9892933 ],\n",
       "       [0.9897533 ],\n",
       "       [0.09350409],\n",
       "       [0.11051445],\n",
       "       [0.94223005],\n",
       "       [0.43791234],\n",
       "       [0.04839881],\n",
       "       [0.02090844],\n",
       "       [0.12571158],\n",
       "       [0.40943584],\n",
       "       [0.83403474],\n",
       "       [0.68500197],\n",
       "       [0.3974862 ],\n",
       "       [0.03701113],\n",
       "       [0.64166135],\n",
       "       [0.04099099],\n",
       "       [0.9383045 ],\n",
       "       [0.9892933 ],\n",
       "       [0.25683716],\n",
       "       [0.06304298],\n",
       "       [0.7165095 ],\n",
       "       [0.9976718 ],\n",
       "       [0.64126456],\n",
       "       [0.14630495],\n",
       "       [0.01215211],\n",
       "       [0.68500185],\n",
       "       [0.02605221],\n",
       "       [0.26895165],\n",
       "       [0.9999701 ],\n",
       "       [0.36977875],\n",
       "       [0.02090844],\n",
       "       [0.9990406 ],\n",
       "       [0.9012434 ],\n",
       "       [0.01215212],\n",
       "       [0.36800748],\n",
       "       [0.9823244 ],\n",
       "       [0.71376115],\n",
       "       [0.5561778 ],\n",
       "       [0.06399499],\n",
       "       [0.867365  ],\n",
       "       [0.5509692 ],\n",
       "       [0.8986183 ],\n",
       "       [0.26309803],\n",
       "       [0.2828566 ],\n",
       "       [0.01989218],\n",
       "       [0.1037814 ],\n",
       "       [0.9588012 ],\n",
       "       [0.01053348],\n",
       "       [0.99769604],\n",
       "       [0.10609074],\n",
       "       [0.26309803],\n",
       "       [0.76693016],\n",
       "       [0.400838  ],\n",
       "       [0.07588718],\n",
       "       [0.9924163 ],\n",
       "       [0.9469451 ],\n",
       "       [0.97202295],\n",
       "       [0.944855  ],\n",
       "       [0.36977875],\n",
       "       [0.05517764],\n",
       "       [0.00131847],\n",
       "       [0.05450518],\n",
       "       [1.        ],\n",
       "       [0.07272306],\n",
       "       [0.58642685],\n",
       "       [0.8769602 ],\n",
       "       [0.09957632],\n",
       "       [0.97372913],\n",
       "       [0.06304298],\n",
       "       [0.968413  ],\n",
       "       [0.32064962],\n",
       "       [0.9795163 ],\n",
       "       [0.7165095 ],\n",
       "       [0.9795163 ],\n",
       "       [0.9989609 ],\n",
       "       [0.10476402],\n",
       "       [0.981008  ],\n",
       "       [0.9927559 ],\n",
       "       [0.9572227 ],\n",
       "       [0.9413164 ],\n",
       "       [0.955316  ],\n",
       "       [0.00367519],\n",
       "       [0.8769539 ],\n",
       "       [0.74033767],\n",
       "       [0.01708091],\n",
       "       [0.1783785 ],\n",
       "       [0.16739021],\n",
       "       [0.00829688],\n",
       "       [0.92239016],\n",
       "       [0.9490505 ],\n",
       "       [0.9012434 ],\n",
       "       [0.79479706],\n",
       "       [0.5315778 ],\n",
       "       [0.00131847],\n",
       "       [0.9996334 ],\n",
       "       [1.        ],\n",
       "       [0.03592532],\n",
       "       [0.9990418 ],\n",
       "       [0.01148348],\n",
       "       [0.74033767],\n",
       "       [0.9990418 ],\n",
       "       [0.9572227 ],\n",
       "       [0.819209  ],\n",
       "       [0.7474937 ],\n",
       "       [0.98256993],\n",
       "       [0.10838281],\n",
       "       [0.4982268 ],\n",
       "       [0.991952  ],\n",
       "       [0.3974862 ],\n",
       "       [0.97183645],\n",
       "       [0.7781278 ],\n",
       "       [0.04741131],\n",
       "       [0.6264389 ],\n",
       "       [0.02090844],\n",
       "       [0.9052908 ],\n",
       "       [0.819209  ],\n",
       "       [0.27555463],\n",
       "       [0.11862212],\n",
       "       [0.9493085 ],\n",
       "       [0.79479706],\n",
       "       [0.12170663],\n",
       "       [0.11051448],\n",
       "       [0.94223005],\n",
       "       [0.98554856],\n",
       "       [0.07272306],\n",
       "       [0.07272306],\n",
       "       [0.29902452],\n",
       "       [0.06742576],\n",
       "       [0.24550198],\n",
       "       [0.01057979],\n",
       "       [0.31490862],\n",
       "       [0.97183645],\n",
       "       [0.36800748],\n",
       "       [0.7578643 ],\n",
       "       [0.9953491 ],\n",
       "       [0.01005479],\n",
       "       [0.8897913 ],\n",
       "       [0.99746066],\n",
       "       [0.999917  ],\n",
       "       [0.007119  ],\n",
       "       [0.58642685],\n",
       "       [0.9916225 ],\n",
       "       [0.9961933 ],\n",
       "       [0.02738595],\n",
       "       [0.9045491 ],\n",
       "       [0.64166135],\n",
       "       [0.4045356 ],\n",
       "       [0.955316  ],\n",
       "       [0.9662897 ],\n",
       "       [0.7165095 ],\n",
       "       [0.88450867],\n",
       "       [0.9888339 ],\n",
       "       [0.974955  ],\n",
       "       [0.5509692 ],\n",
       "       [0.86905235],\n",
       "       [0.64166135],\n",
       "       [0.06304298],\n",
       "       [0.20241886],\n",
       "       [0.97887737],\n",
       "       [0.02745239],\n",
       "       [0.99609697],\n",
       "       [0.99660695],\n",
       "       [0.40863448],\n",
       "       [0.89104795],\n",
       "       [0.99660695],\n",
       "       [0.08558248],\n",
       "       [0.38519272],\n",
       "       [0.18214239],\n",
       "       [0.7228778 ],\n",
       "       [0.9981122 ],\n",
       "       [0.6872974 ],\n",
       "       [0.74033767],\n",
       "       [0.89104795],\n",
       "       [0.09569177],\n",
       "       [0.99989533],\n",
       "       [0.400838  ],\n",
       "       [0.11862212],\n",
       "       [0.16483925],\n",
       "       [0.6435927 ],\n",
       "       [0.24550198],\n",
       "       [0.7808139 ],\n",
       "       [0.03592532],\n",
       "       [0.6830586 ],\n",
       "       [0.01989218],\n",
       "       [0.05450515],\n",
       "       [0.9925555 ],\n",
       "       [0.9290143 ],\n",
       "       [0.846707  ],\n",
       "       [0.9413164 ],\n",
       "       [0.7866864 ],\n",
       "       [0.02446905],\n",
       "       [0.8769539 ],\n",
       "       [0.86905235],\n",
       "       [0.40996298],\n",
       "       [0.82870096],\n",
       "       [0.9493085 ],\n",
       "       [0.04741131],\n",
       "       [0.06399499],\n",
       "       [0.27273956],\n",
       "       [0.18405133],\n",
       "       [0.99338394],\n",
       "       [0.96462506],\n",
       "       [0.71706766],\n",
       "       [0.1647933 ],\n",
       "       [0.9999816 ],\n",
       "       [0.15534429],\n",
       "       [0.02097581],\n",
       "       [0.968413  ],\n",
       "       [0.04839724],\n",
       "       [1.        ],\n",
       "       [0.7628361 ],\n",
       "       [0.19609784],\n",
       "       [0.9823244 ],\n",
       "       [0.27103233],\n",
       "       [0.46388364],\n",
       "       [0.007119  ],\n",
       "       [0.17837845],\n",
       "       [0.9942852 ],\n",
       "       [0.02711118],\n",
       "       [0.8409366 ],\n",
       "       [0.07193814],\n",
       "       [0.9589306 ],\n",
       "       [0.08930292],\n",
       "       [0.4962469 ],\n",
       "       [0.80566686],\n",
       "       [0.12458687],\n",
       "       [0.25683716],\n",
       "       [0.00863103],\n",
       "       [0.04072771],\n",
       "       [0.9996831 ],\n",
       "       [0.16483925],\n",
       "       [0.43813083],\n",
       "       [0.02711118],\n",
       "       [0.3974862 ],\n",
       "       [0.22668792],\n",
       "       [0.9953491 ],\n",
       "       [0.1650294 ],\n",
       "       [0.93905073],\n",
       "       [0.9976903 ],\n",
       "       [0.58170396],\n",
       "       [0.94905037],\n",
       "       [0.9965471 ],\n",
       "       [0.00586954],\n",
       "       [0.7134233 ],\n",
       "       [0.2690302 ],\n",
       "       [0.16483925],\n",
       "       [0.9976903 ],\n",
       "       [0.00586954],\n",
       "       [0.9455167 ],\n",
       "       [0.7866864 ],\n",
       "       [0.06526569],\n",
       "       [0.71376115],\n",
       "       [0.4982268 ],\n",
       "       [0.32064962],\n",
       "       [0.999917  ],\n",
       "       [0.955316  ],\n",
       "       [0.04741131],\n",
       "       [0.95906854],\n",
       "       [0.9976903 ],\n",
       "       [0.01708091],\n",
       "       [0.40943584],\n",
       "       [0.9955909 ],\n",
       "       [0.18214239],\n",
       "       [0.05871695],\n",
       "       [0.99271345],\n",
       "       [0.999917  ],\n",
       "       [0.7781278 ],\n",
       "       [0.08930292],\n",
       "       [0.25771257],\n",
       "       [0.61090165]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d682a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.0097\n",
      "Test Accuracy: 0.009740259498357773\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76487b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
